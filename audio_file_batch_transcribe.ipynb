{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio File Batch Transcription\n",
    "\n",
    "Transcribe audio files using OpenAI Whisper with GPU acceleration.\n",
    "\n",
    "**Supported formats:** .m4a, .mp3, .wav, .flac\n",
    "\n",
    "**Output formats:** .txt, .srt, .vtt, .tsv, .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model\n",
    "import whisper\n",
    "\n",
    "# Model options: tiny, base, small, medium, large\n",
    "# RTX 3070 Ti (8GB VRAM) can handle up to 'large' but 'medium' is faster\n",
    "MODEL_SIZE = \"medium\"\n",
    "\n",
    "print(f\"Loading Whisper {MODEL_SIZE} model...\")\n",
    "model = whisper.load_model(MODEL_SIZE)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Input: single file or folder\n",
    "AUDIO_FILE = Path(\"recordings/test_recording.wav\")  # Change this to your file\n",
    "\n",
    "# Output folder (same as input file location by default)\n",
    "OUTPUT_DIR = AUDIO_FILE.parent\n",
    "\n",
    "print(f\"Audio file: {AUDIO_FILE}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"File exists: {AUDIO_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the audio file\n",
    "import time\n",
    "\n",
    "print(f\"Transcribing: {AUDIO_FILE.name}\")\n",
    "start = time.time()\n",
    "\n",
    "result = model.transcribe(\n",
    "    str(AUDIO_FILE),\n",
    "    language=\"en\",  # Set to None for auto-detect\n",
    "    verbose=True    # Show progress\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\nDone! Took {elapsed:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the transcription\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSCRIPTION\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs in multiple formats\n",
    "from whisper.utils import get_writer\n",
    "\n",
    "base_name = AUDIO_FILE.stem\n",
    "\n",
    "# Save each format\n",
    "for fmt in [\"txt\", \"srt\", \"vtt\", \"tsv\", \"json\"]:\n",
    "    writer = get_writer(fmt, str(OUTPUT_DIR))\n",
    "    writer(result, str(AUDIO_FILE), {})\n",
    "    print(f\"Saved: {OUTPUT_DIR / base_name}.{fmt}\")\n",
    "\n",
    "print(\"\\nAll formats saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Transcription\n",
    "\n",
    "Process multiple audio files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch transcribe all audio files in a folder\n",
    "from pathlib import Path\n",
    "import time\n",
    "from whisper.utils import get_writer\n",
    "\n",
    "INPUT_FOLDER = Path(\"recordings\")\n",
    "EXTENSIONS = [\".m4a\", \".mp3\", \".wav\", \".flac\"]\n",
    "\n",
    "# Find all audio files\n",
    "audio_files = [f for f in INPUT_FOLDER.iterdir() \n",
    "               if f.suffix.lower() in EXTENSIONS]\n",
    "\n",
    "print(f\"Found {len(audio_files)} audio files:\")\n",
    "for f in audio_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file (run this cell to start batch transcription)\n",
    "for i, audio_file in enumerate(audio_files, 1):\n",
    "    print(f\"\\n[{i}/{len(audio_files)}] {audio_file.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Skip if already transcribed\n",
    "    txt_file = audio_file.with_suffix(\".txt\")\n",
    "    if txt_file.exists():\n",
    "        print(\"  Already transcribed, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "    result = model.transcribe(str(audio_file), language=\"en\")\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Save all formats\n",
    "    for fmt in [\"txt\", \"srt\", \"json\"]:\n",
    "        writer = get_writer(fmt, str(INPUT_FOLDER))\n",
    "        writer(result, str(audio_file), {})\n",
    "    \n",
    "    print(f\"  Done in {elapsed:.1f}s\")\n",
    "    print(f\"  Preview: {result['text'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Batch transcription complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
